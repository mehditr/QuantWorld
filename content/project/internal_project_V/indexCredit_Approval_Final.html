---
title: Credit Card Approval
author: ''
date: '2022-10-19'
slug: credit-card-approval
categories: []
tags: []
subtitle: ''
summary: 'EDA and Machine Learning Techniques for Credit Card Approval'
authors: []
lastmod: '2022-10-19T01:39:59+01:00'
featured: no
image:
  caption: 'Image by <a href= "https://image.cnbcfm.com/api/v1/image/106223010-1572903600548gettyimages-1012103320.jpg?v=1572903633&w=740&h=416&ffmt=webp" </a>'
  focal_point: ''
  preview_only: no
projects: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="credit-card-approval" class="section level1">
<h1>Credit Card Approval</h1>
<p>Generally, Banks receive lots of requests for loans or credit card however they cannot accept all.
They use many filterings to their default or overdraft risks coming from their customers. Abviously, it is a lenthy process to do that manually however machine learning ppower can help them to reduced their default risks.
In this notebook I will look at the process of approval credit card based on statistical methond and machine learning approaches</p>
<pre class="python"><code># Import pandas
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import scipy.stats as stats
sns.set(color_codes=True)
from scipy.stats import chisquare,chi2_contingency
from scipy.stats import ttest_ind
from scipy.stats import f_oneway
import warnings
warnings.filterwarnings(&#39;ignore&#39;)
# Load dataset
credit = pd.read_csv(r&#39;C:\Users\X550LD\Desktop\ML\credit_clean.csv&#39;)

# Inspect data
credit.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Gender
</th>
<th>
Age
</th>
<th>
Debt
</th>
<th>
Married
</th>
<th>
BankCustomer
</th>
<th>
Industry
</th>
<th>
Ethnicity
</th>
<th>
YearsEmployed
</th>
<th>
PriorDefault
</th>
<th>
Employed
</th>
<th>
CreditScore
</th>
<th>
DriversLicense
</th>
<th>
Citizen
</th>
<th>
ZipCode
</th>
<th>
Income
</th>
<th>
Approved
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
30.83
</td>
<td>
0.000
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Industrials
</td>
<td>
White
</td>
<td>
1.25
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
0
</td>
<td>
ByBirth
</td>
<td>
202
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
0
</td>
<td>
58.67
</td>
<td>
4.460
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Materials
</td>
<td>
Black
</td>
<td>
3.04
</td>
<td>
1
</td>
<td>
1
</td>
<td>
6
</td>
<td>
0
</td>
<td>
ByBirth
</td>
<td>
43
</td>
<td>
560
</td>
<td>
1
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
24.50
</td>
<td>
0.500
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Materials
</td>
<td>
Black
</td>
<td>
1.50
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
ByBirth
</td>
<td>
280
</td>
<td>
824
</td>
<td>
1
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1
</td>
<td>
27.83
</td>
<td>
1.540
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Industrials
</td>
<td>
White
</td>
<td>
3.75
</td>
<td>
1
</td>
<td>
1
</td>
<td>
5
</td>
<td>
1
</td>
<td>
ByBirth
</td>
<td>
100
</td>
<td>
3
</td>
<td>
1
</td>
</tr>
<tr>
<th>
4
</th>
<td>
1
</td>
<td>
20.17
</td>
<td>
5.625
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Industrials
</td>
<td>
White
</td>
<td>
1.71
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
ByOtherMeans
</td>
<td>
120
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="dealing-with-missing-values" class="section level1">
<h1>1 - Dealing With Missing Values</h1>
<p>In the dataset there are missing values but they have beed replaced with questions mark “?”. So for the first action I replace
the sign with <code>np.NaN</code>, therefore I will deal better with missing values.
Since there are two general types of data, numerical and categorical, we have to use different methods to impute missing values.
For numerical data, mean or median imputation can be applied as our data is not actually imbalanced, and for categorical data as the mean or median aren’t working for them, I would to impute these missing values with the most frequent values as present in the respective columns.
Ignoring the missing values can affect our machine learning model and miss out on information about the dataset that may be useful. The other reason is, some techniques such as Linear Discriminant Analysis (LDA) cannot handle missing values implicilty.</p>
<pre class="python"><code>
# Replace the &#39;?&#39;s with NaN
credit= credit.replace(&#39;?&#39;, np.NaN)

# Impute the missing values on numerical based on mean imputation
credit.fillna(credit.mean(), inplace=True)

# Impute missing values applied on categorical data
for col in credit.columns:
    # Check if the column is of object type
    if credit[col].dtypes == &#39;object&#39;:
        # Impute with the most frequent value
        credit = credit.fillna(credit[col].value_counts().index[0])
</code></pre>
<p>As we have seen, the dataset has different type of variables. Some of them are numerical and the others are categorical.
Age can be an example of numerical type and it is also continous, and Gender is an example of categorical with male and female
that can be masked as 1 and 0. It is important to see what kind of data distinguishes the informative and non-informative.
It is not applicable to see different types of data, especially for categorical data that can be repeatable, so we can see the component of each columns as the following code :</p>
<pre class="python"><code>cat = credit.select_dtypes(&#39;object&#39;).columns
for col in cat:
    print( col, &#39;---&gt;&#39;,credit[col].unique())</code></pre>
<pre><code>Industry ---&gt; [&#39;Industrials&#39; &#39;Materials&#39; &#39;CommunicationServices&#39; &#39;Transport&#39;
 &#39;InformationTechnology&#39; &#39;Financials&#39; &#39;Energy&#39; &#39;Real Estate&#39; &#39;Utilities&#39;
 &#39;ConsumerDiscretionary&#39; &#39;Education&#39; &#39;ConsumerStaples&#39; &#39;Healthcare&#39;
 &#39;Research&#39;]
Ethnicity ---&gt; [&#39;White&#39; &#39;Black&#39; &#39;Asian&#39; &#39;Latino&#39; &#39;Other&#39;]
Citizen ---&gt; [&#39;ByBirth&#39; &#39;ByOtherMeans&#39; &#39;Temporary&#39;]</code></pre>
<pre class="python"><code>
sns.countplot(credit.dtypes.map(str))
plt.show()
# Print DataFrame information
credit_info = credit.info()
print(credit_info)

print(&#39;\n&#39;)
</code></pre>
<p><img src="/img/Credit_Approval_Final_8_0.png" alt="" /></p>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 690 entries, 0 to 689
Data columns (total 16 columns):
 #   Column          Non-Null Count  Dtype  
---  ------          --------------  -----  
 0   Gender          690 non-null    int64  
 1   Age             690 non-null    float64
 2   Debt            690 non-null    float64
 3   Married         690 non-null    int64  
 4   BankCustomer    690 non-null    int64  
 5   Industry        690 non-null    object 
 6   Ethnicity       690 non-null    object 
 7   YearsEmployed   690 non-null    float64
 8   PriorDefault    690 non-null    int64  
 9   Employed        690 non-null    int64  
 10  CreditScore     690 non-null    int64  
 11  DriversLicense  690 non-null    int64  
 12  Citizen         690 non-null    object 
 13  ZipCode         690 non-null    int64  
 14  Income          690 non-null    int64  
 15  Approved        690 non-null    int64  
dtypes: float64(3), int64(10), object(3)
memory usage: 86.4+ KB
None</code></pre>
</div>
<div id="exploratory-data-analysis" class="section level1">
<h1>2 - Exploratory Data Analysis</h1>
<p>Now, we have a first impression of data. The probable features in a typical credit card application are <code>Gender</code>, <code>Age</code>, <code>Debt</code>, <code>Married</code>, <code>BankCustomer</code>, <code>EducationLevel</code>, <code>Ethnicity</code>, <code>YearsEmployed</code>, <code>PriorDefault</code>, <code>Employed</code>, <code>CreditScore</code>, <code>DriversLicense</code>, <code>Citizen</code>, <code>ZipCode</code>, <code>Income</code> and finally the <code>ApprovalStatus</code>. This would be a good staring point for us, but we are not still aware of the importance of features. At the first step, I will ignore some features like <code>DriversLicense</code> and <code>ZipCode</code> as they are not informative as the other features in the dataset for predicting credit card approvals. To get a better sense, we can apply some hypothesis testing along with their visualizations to see what features are probably more important the others</p>
<pre class="python"><code>plt.figure(figsize=(20,7),dpi=300)

sns.countplot(data=credit,x=&#39;Industry&#39;,hue=&#39;Approved&#39;)
plt.title(&#39;Figure_1 - Approved and Not Approved Based on Industry&#39;)

plt.tight_layout()</code></pre>
<div class="figure">
<img src="Credit_Approval_Final_files/Credit_Approval_Final_10_0.png" alt="" />
<p class="caption">png</p>
</div>
<pre class="python"><code>Perc_App_Ind = pd.DataFrame(round(credit.loc[:,[&#39;Approved&#39;,&#39;Industry&#39;]].groupby(&#39;Industry&#39;).sum()/
                                  credit.loc[:,[&#39;Approved&#39;,&#39;Industry&#39;]].groupby(&#39;Industry&#39;).count(),2))
Perc_App_Ind.sort_values(&#39;Approved&#39;,ascending=False)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Approved
</th>
</tr>
<tr>
<th>
Industry
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
Utilities
</th>
<td>
0.84
</td>
</tr>
<tr>
<th>
InformationTechnology
</th>
<td>
0.71
</td>
</tr>
<tr>
<th>
Transport
</th>
<td>
0.67
</td>
</tr>
<tr>
<th>
Materials
</th>
<td>
0.65
</td>
</tr>
<tr>
<th>
Education
</th>
<td>
0.56
</td>
</tr>
<tr>
<th>
Industrials
</th>
<td>
0.52
</td>
</tr>
<tr>
<th>
Energy
</th>
<td>
0.45
</td>
</tr>
<tr>
<th>
CommunicationServices
</th>
<td>
0.42
</td>
</tr>
<tr>
<th>
ConsumerStaples
</th>
<td>
0.35
</td>
</tr>
<tr>
<th>
Research
</th>
<td>
0.30
</td>
</tr>
<tr>
<th>
Financials
</th>
<td>
0.27
</td>
</tr>
<tr>
<th>
ConsumerDiscretionary
</th>
<td>
0.24
</td>
</tr>
<tr>
<th>
Real Estate
</th>
<td>
0.23
</td>
</tr>
<tr>
<th>
Healthcare
</th>
<td>
0.13
</td>
</tr>
</tbody>
</table>
</div>
<p>So,‘Figure_1’ shows which industries people are coming from, and they have been approved or not approved.
So basically some industries such as <code>Healthcare</code> or <code>Consumer Discretionary</code> are more failed.
Therefore that <code>Industry</code> can be a potential feature as an important one.</p>
<pre class="python"><code>sns.displot(data=credit,x=&#39;Age&#39;,bins=30,kde=True,hue=&#39;Approved&#39;)
plt.annotate(&#39;Two Tails cross&#39;, xy=(55, 10), xytext=(60,23),
            arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05))
plt.title (&#39; Figure_2 : Approved and UnApproved base on Age Distribution&#39;)
plt.show()</code></pre>
<p><img src="/img/Credit_Approval_Final_13_0" alt="" /><br />
<img src="Credit_Approval_Final_files/Credit_Approval_Final_13_0.png" alt="png" /></p>
<p>The second graph is an interesting one. In general, there are many reasons why a bank will reject applications when a person has a low or moderate income or does not have enough funds to support themselves against debts, and this happens more often in the early years of work. . Therefore, according to the graph, it is possible to see the ages below 40 years (almost or slightly less than 40 years), the number of unapproved applications is more than one approved one.
After 40 (or under 40) the number of endorsements increases, which tells us that age is an informative characteristic.</p>
<pre class="python"><code>plt.figure(figsize=(4,4))

plt.pie(credit[&#39;Approved&#39;].value_counts(),colors=[&#39;g&#39;,&#39;pink&#39;]
        ,explode=[0.03,0.03],autopct=&#39;%.2f&#39;,shadow=5,radius=1.1)

plt.tight_layout()
plt.title(&#39;Figure_3 : Approx. Balanced Data&#39;)
plt.show()
print(pd.crosstab(credit.Approved, credit.Approved))</code></pre>
<div class="figure">
<img src="Credit_Approval_Final_files/Credit_Approval_Final_15_0.png" alt="" />
<p class="caption">png</p>
</div>
<pre><code>Approved    0    1
Approved          
0         383    0
1           0  307</code></pre>
<p>Figure_3: As I mentioned earlier, our data set is not imbalanced. In general, data sets for predicting default rates or detecting fraud are imbalanced data. Working with imbalanced data requires techniques to obtain meaningful output and is beyond the scope of this project. As we can see here, the number of approved credit cards and 307 unapproved credit cards is 383.</p>
<pre class="python"><code>sig_Item =credit.groupby(&#39;Approved&#39;)[&#39;Age&#39;,&#39;Debt&#39;,&#39;CreditScore&#39;,&#39;Income&#39;].mean()
pd.DataFrame(sig_Item)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Age
</th>
<th>
Debt
</th>
<th>
CreditScore
</th>
<th>
Income
</th>
</tr>
<tr>
<th>
Approved
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
29.773029
</td>
<td>
3.839948
</td>
<td>
0.631854
</td>
<td>
198.605744
</td>
</tr>
<tr>
<th>
1
</th>
<td>
33.686221
</td>
<td>
5.904951
</td>
<td>
4.605863
</td>
<td>
2038.859935
</td>
</tr>
</tbody>
</table>
</div>
<p>In the table above, we can see some continuous features separated by the “Approved” column. Except for age, all have significant differences in their means. Particularly, there are noticeable large gaps in average income and credit scores. So here it is good to check their graphs and see their distribution.</p>
<pre class="python"><code>plt.figure(figsize=(15,8))

plt.subplot(2,2,1)
sns.boxplot(data=credit,x=&#39;Approved&#39;,y=&#39;Age&#39;)

plt.subplot(2,2,2)
sns.boxplot(data=credit,x=&#39;Approved&#39;,y=&#39;Debt&#39;)

plt.subplot(2,2,3)
sns.boxplot(data=credit,x=&#39;Approved&#39;,y=&#39;CreditScore&#39;)

plt.subplot(2,2,4)
sns.boxplot(data=credit,x=&#39;Approved&#39;,y=&#39;Income&#39;)

plt.tight_layout()
plt.show()</code></pre>
<div class="figure">
<img src="Credit_Approval_Final_files/Credit_Approval_Final_19_0.png" alt="" />
<p class="caption">png</p>
</div>
<p>The second row graphs demonstrate some weird points that can be outliers. Let’s try to see what is the characteristics of those two highest points in credit score and income</p>
<pre class="python"><code>print(&#39;The highest point in Credit Score :&#39;)
print(&#39;\n&#39;)
maxim_1 = credit[&#39;CreditScore&#39;].idxmax()
print(credit[[&#39;Age&#39;,&#39;Debt&#39;,&#39;CreditScore&#39;,&#39;Income&#39;,&#39;Industry&#39;]].iloc[maxim_1])

print(&#39;------------------------------------&#39;)

print(&#39;The highest point in Income :&#39;)
print(&#39;\n&#39;)
maxim_2 = credit[&#39;Income&#39;].idxmax()
print( credit[[&#39;Age&#39;,&#39;Debt&#39;,&#39;CreditScore&#39;,&#39;Income&#39;,&#39;Industry&#39;]].iloc[maxim_2])
</code></pre>
<pre><code>The highest point in Credit Score :


Age                            25.67
Debt                            12.5
CreditScore                       67
Income                           258
Industry       InformationTechnology
Name: 121, dtype: object
------------------------------------
The highest point in Income :


Age                  17.5
Debt                 22.0
CreditScore             0
Income             100000
Industry       Healthcare
Name: 317, dtype: object</code></pre>
<pre class="python"><code>maxim_2 = credit[&#39;Income&#39;].idxmax()
credit[[&#39;Age&#39;,&#39;Debt&#39;,&#39;CreditScore&#39;,&#39;Income&#39;,&#39;Industry&#39;]].iloc[maxim_2]</code></pre>
<pre><code>Age                  17.5
Debt                 22.0
CreditScore             0
Income             100000
Industry       Healthcare
Name: 317, dtype: object</code></pre>
<p>The interesting thing to note here is that the highest credit score is related to the IT industry, which ranks second in “approved” programs. However, the highest revenue comes from the healthcare industry, which is the last industry to receive an approved application and both have the same amount of debt. Is there bias in these decisions?!!!!!!
That can be a trigger for data scientists !!!</p>
<pre class="python"><code>Customer = credit[credit[&#39;BankCustomer&#39;]==1]
Non_Customer = credit[credit[&#39;BankCustomer&#39;]==0]

g = sns.FacetGrid(credit, col=&quot;Approved&quot;,  row=&quot;BankCustomer&quot;)
g.map_dataframe(sns.histplot, x=&quot;Debt&quot;)
plt.annotate(&#39;More Debt&#39;, xy=(20, 5), xytext=(30,23),
            arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05))
g.fig.subplots_adjust(top=0.85) 
g.fig.suptitle(&#39;Figure_5&#39;)
plt.show()</code></pre>
<div class="figure">
<img src="Credit_Approval_Final_files/Credit_Approval_Final_24_0.png" alt="" />
<p class="caption">png</p>
</div>
<p>Figure_5 : There is an argue that some bank customers who are approved by the bank have more debt than others who are not their customers. In the figure above, I have split the data based on the “Bank Customer” and “Verified” attributes.
This graph shows that bank customers have more debts than those who are not, and this difference is significant.</p>
</div>
<div id="machine-learning-techniques" class="section level1">
<h1>3 - Machine Learning Techniques</h1>
<p>In this section, I will use two techniques Logistics regression and Support Vector Machines for classifying the data.</p>
<p><strong>3-1 : Logistic Regression</strong></p>
<pre class="python"><code># removing non-informative columns
df = credit.copy()
df = df.drop([&#39;DriversLicense&#39;,&#39;ZipCode&#39;],axis=1)</code></pre>
<pre class="python"><code>df = pd.get_dummies(df)
df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Gender
</th>
<th>
Age
</th>
<th>
Debt
</th>
<th>
Married
</th>
<th>
BankCustomer
</th>
<th>
YearsEmployed
</th>
<th>
PriorDefault
</th>
<th>
Employed
</th>
<th>
CreditScore
</th>
<th>
Income
</th>
<th>
…
</th>
<th>
Industry_Transport
</th>
<th>
Industry_Utilities
</th>
<th>
Ethnicity_Asian
</th>
<th>
Ethnicity_Black
</th>
<th>
Ethnicity_Latino
</th>
<th>
Ethnicity_Other
</th>
<th>
Ethnicity_White
</th>
<th>
Citizen_ByBirth
</th>
<th>
Citizen_ByOtherMeans
</th>
<th>
Citizen_Temporary
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
30.83
</td>
<td>
0.000
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1.25
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
<td>
0
</td>
<td>
…
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
0
</td>
<td>
58.67
</td>
<td>
4.460
</td>
<td>
1
</td>
<td>
1
</td>
<td>
3.04
</td>
<td>
1
</td>
<td>
1
</td>
<td>
6
</td>
<td>
560
</td>
<td>
…
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
24.50
</td>
<td>
0.500
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1.50
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
824
</td>
<td>
…
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1
</td>
<td>
27.83
</td>
<td>
1.540
</td>
<td>
1
</td>
<td>
1
</td>
<td>
3.75
</td>
<td>
1
</td>
<td>
1
</td>
<td>
5
</td>
<td>
3
</td>
<td>
…
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
1
</td>
<td>
20.17
</td>
<td>
5.625
</td>
<td>
1
</td>
<td>
1
</td>
<td>
1.71
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
…
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
<p>
5 rows × 33 columns
</p>
</div>
<p>Since there are a number of categorical variables, I use a method called “One Hot Encode” which is suitable when there is no relationship between the categorical variables. For example, we can see that the industry attribute is divided by industry names and their values are 0 and 1. Since our goal is to use models to get the right classification and predict new customers, we need to scale our data, so the mentioned method should be used.</p>
<pre class="python"><code>from sklearn.preprocessing import MinMaxScaler
</code></pre>
<pre class="python"><code>scaler= MinMaxScaler(feature_range=(0,1))
scaled_df = scaler.fit_transform(df)
scaled_df = pd.DataFrame(scaled_df,columns=df.columns)
scaled_df[&#39;Approved&#39;]=df[&#39;Approved&#39;]</code></pre>
<pre class="python"><code>y= scaled_df[&#39;Approved&#39;]
X= scaled_df.drop(&#39;Approved&#39;,axis=1)

from sklearn.model_selection import train_test_split

X_train,X_test, y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=1000)
</code></pre>
<pre class="python"><code>from sklearn.linear_model import LogisticRegression

log_model = LogisticRegression()
log_model.fit(X_train,y_train)
</code></pre>
<pre><code>LogisticRegression()</code></pre>
<pre class="python"><code>from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,f1_score,precision_score

y_pred = log_model.predict(X_test)
y_pred_train = log_model.predict(X_train)
print(&#39;Accuracy of logistic model is for Train \t:&#39;, round(log_model.score(X_train,y_train ),3))
print(&#39;Accuracy of logistic model is for Test \t\t:&#39;, round(log_model.score(X_test,y_test),3))
#log_model.score
print(&#39;Recall of logistic model is for Test \t\t:&#39;, round(recall_score(y_test,y_pred),3))
print(&#39;f1_score of logistic model is for Test \t\t:&#39;, round(f1_score(y_test,y_pred),3))
print(&#39;Precision of logistic model is for Test \t:&#39;, round(precision_score(y_test,y_pred),3))

confusion_matrix(y_test,y_pred)
</code></pre>
<pre><code>Accuracy of logistic model is for Train     : 0.87
Accuracy of logistic model is for Test      : 0.868
Recall of logistic model is for Test        : 0.871
f1_score of logistic model is for Test      : 0.871
Precision of logistic model is for Test     : 0.871





array([[ 97,  15],
       [ 15, 101]], dtype=int64)</code></pre>
<pre class="python"><code>from sklearn.model_selection import GridSearchCV

tol = [0.01,0.001,0.0001]
max_iter = [100,150,200]

param_grid = dict(tol=tol,max_iter = max_iter)</code></pre>
<pre class="python"><code>grid_model = GridSearchCV(estimator = log_model, param_grid = param_grid ,cv= 5)

grid_model_output = grid_model.fit(X_train,y_train)

best_score, best_params = grid_model_output.best_score_ , grid_model_output.best_params_

best_model = grid_model_output.best_estimator_
print(&quot; The Accuracy is for Test is \t\t:&quot;, best_model.score(X_test,y_test))

</code></pre>
<pre><code> The Accuracy is for Test is        : 0.868421052631579</code></pre>
<p>I have run the logistic regression and for the first part I have reach good result for both train and test about 87%. This shows that almost the model is not overfitted since both the accuracy of train and test are close to each other.
For getting the better result, I have applied a method call ‘GridSearchCV’. Generally, Grid search procedure is used for tuning hyperparameters and fit the learner on train and validation ( or test) sets repeatedly and in the end find a best pramaeter for the model.
After applying this method on and trying ti get the result with best parameters, I have reach again the accuracy of test as the same as previous one.</p>
<p><strong>3-2 Support Vector Machine</strong></p>
<pre class="python"><code>from sklearn.svm import SVC</code></pre>
<pre class="python"><code>SVM_model = SVC()
SVM_model.fit(X_train,y_train)</code></pre>
<pre><code>SVC()</code></pre>
<pre class="python"><code>y_hat = SVM_model.predict(X_test)</code></pre>
<pre class="python"><code>prediction = pd.DataFrame({&#39;y_test&#39;:y_test,&#39;y_hat&#39;:y_hat})
prediction</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
y_test
</th>
<th>
y_hat
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
389
</th>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
609
</th>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
393
</th>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
195
</th>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
338
</th>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
64
</th>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
353
</th>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
267
</th>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
162
</th>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
638
</th>
<td>
0
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
<p>
228 rows × 2 columns
</p>
</div>
<pre class="python"><code>from sklearn.metrics import accuracy_score,precision_score,recall_score, f1_score, confusion_matrix


def SVM_report(X_train,y_train,X_test,y_test,C=1,gamma=&#39;scale&#39;,kernel=&#39;rbf&#39;,class_weight = None):
    svc=SVC(C=C,gamma=gamma,kernel=kernel,class_weight = class_weight)
    svc.fit(X_train,y_train)
    y_hat=svc.predict(X_test)
    
    cm = confusion_matrix(y_test,y_hat)
    accuracy = round(accuracy_score(y_test,y_hat),4)
    error_rate= round((1-accuracy),4)
    precision = round(precision_score(y_test,y_hat),2)
    recall = round(recall_score(y_test,y_hat),2)
    f1score = round(f1_score(y_test,y_hat),2)
    cm_labled = pd.DataFrame(cm, index=[&#39;Actual : negative&#39;,&#39;Actual : positive&#39;],columns=[&#39;Predict : negative&#39;,&#39;Predict: positive&#39;])
    
    print(&#39;The metrics are as follow :&#39;)
    
    print(&#39;Accuracy = {}&#39;.format(accuracy))
    print(&#39;error_rate = {}&#39;.format(error_rate))
    print(&#39;precision = {}&#39;.format(precision))
    print(&#39;recall = {}&#39;.format(recall))
    print(&#39;f1score = {}&#39;.format(f1score))
    
    return cm_labled</code></pre>
<pre class="python"><code>SVM_report(X_train,y_train,X_test,y_test,kernel=&#39;rbf&#39;)</code></pre>
<pre><code>The metrics are as follow :
Accuracy = 0.8816
error_rate = 0.1184
precision = 0.87
recall = 0.9
f1score = 0.89</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Predict : negative
</th>
<th>
Predict: positive
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
Actual : negative
</th>
<td>
97
</td>
<td>
15
</td>
</tr>
<tr>
<th>
Actual : positive
</th>
<td>
12
</td>
<td>
104
</td>
</tr>
</tbody>
</table>
</div>
<p>We can see an improvment in all metrics regarding to logistic regression in the first step. Now I would like to tune the hyperparameters in SVM. For this reason, I will apply an approach call kernel tricks. As the shape of logistic regression is ‘S’ shape and the function of logistic regression is ‘Sigmoid’, I will implement another kernels such as ’ Radial Basis Function’( or’rbf’) and ‘Polynomial’ (or ‘poly’) for tuning.</p>
</div>
<div id="tuning-hyperparameters" class="section level1">
<h1>Tuning Hyperparameters</h1>
<pre class="python"><code>from sklearn.metrics import accuracy_score,precision_score,recall_score, f1_score, confusion_matrix,make_scorer
my_param_grid ={&#39;C&#39;:[10,100,1000],&#39;gamma&#39;:[&#39;scale&#39;,0.01,0.001], &#39;kernel&#39;:[&#39;rbf&#39;,&#39;poly&#39;]}
f1=make_scorer(f1_score)</code></pre>
<pre class="python"><code>grid = GridSearchCV(estimator = SVC(),param_grid = my_param_grid, refit=True,verbose=2, cv=5, scoring=f1)</code></pre>
<pre class="python"><code>grid.fit(X_train,y_train)</code></pre>
<pre><code>Fitting 5 folds for each of 18 candidates, totalling 90 fits
[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.1s
[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END .....................C=10, gamma=scale, kernel=poly; total time=   0.0s
[CV] END .....................C=10, gamma=scale, kernel=poly; total time=   0.0s
[CV] END .....................C=10, gamma=scale, kernel=poly; total time=   0.0s
[CV] END .....................C=10, gamma=scale, kernel=poly; total time=   0.0s
[CV] END .....................C=10, gamma=scale, kernel=poly; total time=   0.0s
[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END ....................C=100, gamma=scale, kernel=poly; total time=   0.0s
[CV] END ....................C=100, gamma=scale, kernel=poly; total time=   0.0s
[CV] END ....................C=100, gamma=scale, kernel=poly; total time=   0.0s
[CV] END ....................C=100, gamma=scale, kernel=poly; total time=   0.0s
[CV] END ....................C=100, gamma=scale, kernel=poly; total time=   0.0s
[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END ....................C=1000, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END ....................C=1000, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END ....................C=1000, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END ....................C=1000, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END ....................C=1000, gamma=scale, kernel=rbf; total time=   0.0s
[CV] END ...................C=1000, gamma=scale, kernel=poly; total time=   0.0s
[CV] END ...................C=1000, gamma=scale, kernel=poly; total time=   0.0s
[CV] END ...................C=1000, gamma=scale, kernel=poly; total time=   0.0s
[CV] END ...................C=1000, gamma=scale, kernel=poly; total time=   0.0s
[CV] END ...................C=1000, gamma=scale, kernel=poly; total time=   0.0s
[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END ....................C=1000, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END ....................C=1000, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END ....................C=1000, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END ....................C=1000, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END ....................C=1000, gamma=0.01, kernel=poly; total time=   0.0s
[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s
[CV] END ...................C=1000, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END ...................C=1000, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END ...................C=1000, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END ...................C=1000, gamma=0.001, kernel=poly; total time=   0.0s
[CV] END ...................C=1000, gamma=0.001, kernel=poly; total time=   0.0s





GridSearchCV(cv=5, estimator=SVC(),
             param_grid={&#39;C&#39;: [10, 100, 1000], &#39;gamma&#39;: [&#39;scale&#39;, 0.01, 0.001],
                         &#39;kernel&#39;: [&#39;rbf&#39;, &#39;poly&#39;]},
             scoring=make_scorer(f1_score), verbose=2)</code></pre>
<p>Since we have 3 states of <code>‘C’</code> and 3 states of <code>‘gamma’</code> and 2 states of <code>‘kernel’</code> and 5 cross validation, the total fiiting will be 90 fit cases</p>
<pre class="python"><code>grid.best_params_</code></pre>
<pre><code>{&#39;C&#39;: 10, &#39;gamma&#39;: 0.01, &#39;kernel&#39;: &#39;rbf&#39;}</code></pre>
<pre class="python"><code>grid.best_estimator_</code></pre>
<pre><code>SVC(C=10, gamma=0.01)</code></pre>
<pre class="python"><code>y_hat_optimized = grid.predict(X_test)</code></pre>
<pre class="python"><code>prediction[&#39;y_hat_optimized&#39;]=y_hat_optimized
prediction.tail(20)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
y_test
</th>
<th>
y_hat
</th>
<th>
y_hat_optimized
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
565
</th>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
218
</th>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
157
</th>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
431
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
1
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<th>
294
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
588
</th>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
527
</th>
<td>
0
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
30
</th>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
159
</th>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
368
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
329
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
273
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
426
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
64
</th>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
353
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
267
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
162
</th>
<td>
1
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
<tr>
<th>
638
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
</div>
<pre class="python"><code>SVM_report(X_train,y_train,X_test,y_test,C=10,gamma=0.01,kernel=&#39;rbf&#39;)</code></pre>
<pre><code>The metrics are as follow :
Accuracy = 0.8772
error_rate = 0.1228
precision = 0.84
recall = 0.93
f1score = 0.89</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Predict : negative
</th>
<th>
Predict: positive
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
Actual : negative
</th>
<td>
92
</td>
<td>
20
</td>
</tr>
<tr>
<th>
Actual : positive
</th>
<td>
8
</td>
<td>
108
</td>
</tr>
</tbody>
</table>
</div>
<p>In the last step for SVM, we see an improvment in <code>‘recall’</code> but a decrease in <code>‘Accuracy’</code>. Sometimes in classification problems, data scientists look at the <code>‘f1_score’</code> and then <code>‘recall’</code>. For those who consider the weight of <code>‘f1_score’</code> and <code>‘recall’</code> more in classification, this result might be valuable.</p>
</div>
